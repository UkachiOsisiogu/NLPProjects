{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "imdb = pd.read_csv('imdb.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      "review       50000 non-null object\n",
      "sentiment    50000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = []\n",
    "negetive = []  \n",
    "def separate(row):\n",
    "    \n",
    "    if row['sentiment'] == 'positive':\n",
    "        positive.append(row['review'])\n",
    "        \n",
    "    else:\n",
    "        negetive.append(row['review'])\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.apply(separate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25002"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negetive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I\\'ve just watched Fingersmith, and I\\'m stunned to see the 8/10 average rating for the show.<br /><br />Not only was the plot was difficult to follow, but it seems character development was randomly applied.<br /><br />The actors were adequate, but in the process of attempting to create twists and turns, their characters are rendered entirely one dimensional. Once this happens, the story really falls flat and becomes tedious.<br /><br />And just in case anyone didn\\'t see the predictable lesbian undertones from miles way, this is hammered home in the most banal terms at the end of the film.<br /><br />The end scene is disappointing and phoned in, and anyone who sat back and went \"Ohhh, so they were carpet munchers all along!\", must have been out for the evening.<br /><br />Two stars for the tonsil hockey in the earlier scene which was at least a bit raunchy, none for the rest of it...'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negetive[32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ukachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ukachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import nltk\n",
    "\n",
    "# nltk.download('all')\n",
    "from nltk.tokenize import sent_tokenize  # tokenizes sentences\n",
    "import re\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "eng_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Preparing the data set for classificationÂ¶\n",
    "Create a function called review_cleaner that reads in a review and:\n",
    "\n",
    "Removes HTML tags (using beautifulsoup)\n",
    "\n",
    "Extract emoticons (emotion symbols, aka smileys :D )\n",
    "\n",
    "Removes non-letters (using regular expression)\n",
    "\n",
    "Converts all words to lowercase letters and tokenizes them (using .split() method on the review strings, so that every word in the review is an element in a list)\n",
    "\n",
    "Removes all the English stopwords from the list of movie review words\n",
    "\n",
    "Join the words back into one string seperated by space, append the emoticons to the end\n",
    "(Transform the list of stopwords to a set before removing the stopwords. Use the set to look up stopwords.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def review_cleaner(reviews, lemmatize=True, stem=False):\n",
    "    \"\"\"\n",
    "    Clean and preprocess a review.\n",
    "\n",
    "    1. Remove HTML tags\n",
    "    2. Use regex to remove all special characters (only keep letters)\n",
    "    3. Make strings to lower case and tokenize / word split reviews\n",
    "    4. Remove English stopwords\n",
    "    5. Rejoin to one string\n",
    "    \"\"\"\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    # 1. Remove HTML tags\n",
    "\n",
    "    cleaned_reviews = []\n",
    "    for i, review in enumerate(reviews):\n",
    "        # print progress\n",
    "        if (i + 1) % 500 == 0:\n",
    "            print(\"Done with %d reviews\" % (i + 1))\n",
    "        review = bs.BeautifulSoup(review).text\n",
    "\n",
    "        # 2. Use regex to find emoticons\n",
    "        emoticons = re.findall(\"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", review)\n",
    "\n",
    "        # 3. Remove punctuation\n",
    "        review = re.sub(\"[^a-zA-Z]\", \" \", review)\n",
    "\n",
    "        # 4. Tokenize into words (all lower case)\n",
    "        review = review.lower().split()\n",
    "\n",
    "        # 5. Remove stopwords\n",
    "        eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "        clean_review = []\n",
    "        for word in review:\n",
    "            if word not in eng_stopwords:\n",
    "                if lemmatize is True:\n",
    "                    word = wnl.lemmatize(word)\n",
    "                elif stem is True:\n",
    "                    if word == \"oed\":\n",
    "                        continue\n",
    "                    word = ps.stem(word)\n",
    "                clean_review.append(word)\n",
    "\n",
    "        # 6. Join the review to one sentence\n",
    "\n",
    "        review_processed = \" \".join(clean_review + emoticons)\n",
    "        cleaned_reviews.append(review_processed)\n",
    "\n",
    "    return cleaned_reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 500 reviews\n",
      "Done with 1000 reviews\n",
      "Done with 1500 reviews\n",
      "Done with 2000 reviews\n",
      "Done with 2500 reviews\n",
      "Done with 3000 reviews\n",
      "Done with 3500 reviews\n",
      "Done with 4000 reviews\n",
      "Done with 4500 reviews\n",
      "Done with 5000 reviews\n",
      "Done with 5500 reviews\n",
      "Done with 6000 reviews\n",
      "Done with 6500 reviews\n",
      "Done with 7000 reviews\n",
      "Done with 7500 reviews\n",
      "Done with 8000 reviews\n",
      "Done with 8500 reviews\n",
      "Done with 9000 reviews\n",
      "Done with 9500 reviews\n",
      "Done with 10000 reviews\n",
      "Done with 10500 reviews\n",
      "Done with 11000 reviews\n",
      "Done with 11500 reviews\n",
      "Done with 12000 reviews\n",
      "Done with 12500 reviews\n",
      "Done with 13000 reviews\n",
      "Done with 13500 reviews\n",
      "Done with 14000 reviews\n",
      "Done with 14500 reviews\n",
      "Done with 15000 reviews\n",
      "Done with 15500 reviews\n",
      "Done with 16000 reviews\n",
      "Done with 16500 reviews\n",
      "Done with 17000 reviews\n",
      "Done with 17500 reviews\n",
      "Done with 18000 reviews\n",
      "Done with 18500 reviews\n",
      "Done with 19000 reviews\n",
      "Done with 19500 reviews\n",
      "Done with 20000 reviews\n",
      "Done with 20500 reviews\n",
      "Done with 21000 reviews\n",
      "Done with 21500 reviews\n",
      "Done with 22000 reviews\n",
      "Done with 22500 reviews\n",
      "Done with 23000 reviews\n",
      "Done with 23500 reviews\n",
      "Done with 24000 reviews\n",
      "Done with 24500 reviews\n",
      "Done with 25000 reviews\n"
     ]
    }
   ],
   "source": [
    "cleaned_positive = review_cleaner(positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use word called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangsta latino christian italian irish scuffle death stare dodgy dealing shady agreement never far away would say main appeal show due fact go show dare forget pretty picture painted mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard sold nickel inmate kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_positive[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_negetive = review_cleaner(negetive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heard good thing state grace came open mind thought god army okay thought maybe dutcher improved matured filmmaker film began shaky acting thought well maybe get better unfortunately never picture start introducing two elder mormon missionary seems audience get know grow care instead story degenerate highly improbable series unfortunate event highlighting blatant disobedience missionary something undeniably exists rarely level dutcher portrays becomes almost laughable dutcher success movie successful alienation target audience unrealistically inaccurately portraying life mormon missionary dutcher accomplishes nothing angering predominantly mormon audience film way reflects reality mission nothing like dutcher show served mormon mission attest fact gang life california certainly contains much explicit language occasional mild vulgarity conclusion assuming supposed touch audience inspire believe forgiveness available unbelievable c mon entire mission gather see elder sent home mom girl standing right next cheesy next time dutcher try making movie someone identify'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_negetive[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we pickle these cleaned lists we can use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cleaned_negetive.pkl', 'wb') as f:\n",
    "    pickle.dump(cleaned_negetive, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"negative_processed_2.txt\", 'w') as output:\n",
    "    for row in cleaned_negetive:\n",
    "        output.write(str(row) + '\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
